# ğŸ—£ï¸ Speech Emotion Detection using Conv1D + LSTM

A **user-driven speech emotion detection system** powered by deep learning!  
This project combines **Conv1D** and **LSTM** layers to effectively capture emotional patterns in voice data â€” giving machines a way to understand how we feel. ğŸ¯

---

## ğŸ§  Overview

Built using deep learning techniques, this model can identify human emotions from speech audio. Whether you're curious about machine perception or building emotion-aware applications, this system is a great starting point.

---

## ğŸ§° Tech Stack

- ğŸ§ª **TensorFlow** â€“ for building and training the neural network  
- ğŸ¶ **libROSA** â€“ for audio processing and feature extraction  
- ğŸ¤ **PyAudio** â€“ for recording live user voice samples

---

## ğŸ’¡ What You Can Do

1. ğŸ” **Retrain the Model**  
   - Re-train the entire model from scratch (takes approx. **1 hour** on a GeForce GTX 1650 GPU)

2. ğŸ² **Test with Sample Voices**  
   - Randomly select built-in voice samples and compare **actual vs predicted** emotions

3. ğŸ™ï¸ **Use Your Own Voice**  
   - Record your voice live and let the model detect your emotion in real-time!

---

## âš ï¸ Limitations

> "Emotions are complex â€” even humans donâ€™t always agree."

- â— Emotion annotation is **subjective** and varies across individuals and cultures  
- ğŸ“¦ There is **no perfect dataset** for emotional speech detection  
- ğŸ§ª Real-world emotion detection remains an evolving challenge

---

## ğŸš€ Coming Soon (Ideas)

- ğŸ“Š Real-time dashboard to visualize prediction probabilities  
- ğŸŒ Multilingual emotion detection support  
- ğŸ¤– Integration with virtual assistants or chatbot platforms
