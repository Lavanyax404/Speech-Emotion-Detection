# 🗣️ Speech Emotion Detection using Conv1D + LSTM

A **user-driven speech emotion detection system** powered by deep learning!  
This project combines **Conv1D** and **LSTM** layers to effectively capture emotional patterns in voice data — giving machines a way to understand how we feel. 🎯

---

## 🧠 Overview

Built using deep learning techniques, this model can identify human emotions from speech audio. Whether you're curious about machine perception or building emotion-aware applications, this system is a great starting point.

---

## 🧰 Tech Stack

- 🧪 **TensorFlow** – for building and training the neural network  
- 🎶 **libROSA** – for audio processing and feature extraction  
- 🎤 **PyAudio** – for recording live user voice samples

---

## 💡 What You Can Do

1. 🔁 **Retrain the Model**  
   - Re-train the entire model from scratch (takes approx. **1 hour** on a GeForce GTX 1650 GPU)

2. 🎲 **Test with Sample Voices**  
   - Randomly select built-in voice samples and compare **actual vs predicted** emotions

3. 🎙️ **Use Your Own Voice**  
   - Record your voice live and let the model detect your emotion in real-time!

---

## ⚠️ Limitations

> "Emotions are complex — even humans don’t always agree."

- ❗ Emotion annotation is **subjective** and varies across individuals and cultures  
- 📦 There is **no perfect dataset** for emotional speech detection  
- 🧪 Real-world emotion detection remains an evolving challenge

---

## 🚀 Coming Soon (Ideas)

- 📊 Real-time dashboard to visualize prediction probabilities  
- 🌍 Multilingual emotion detection support  
- 🤖 Integration with virtual assistants or chatbot platforms
